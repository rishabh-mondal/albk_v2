{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from astra.torch.models import EfficientNet,ResNetClassifier, MLP, MLPClassifier, EfficientNetClassifier\n",
        "# from astra.torch.utils import count_params\n",
        "# print(count_params(EfficientNetClassifier()))\n",
        "# print(count_params(ResNetClassifier()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iXESJ2O74nhU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import random_split\n",
        "from torchvision.utils import make_grid\n",
        "import torch.nn as nn\n",
        "import copy\n",
        "import time\n",
        "import os\n",
        "import torchvision.models as models\n",
        "\n",
        "import argparse\n",
        "from torch.utils.data import Subset\n",
        "import csv\n",
        "device = torch.device('cuda')\n",
        "from ResNet import *\n",
        "from sklearn.metrics import confusion_matrix,f1_score,accuracy_score,precision_score,recall_score\n",
        "from sklearn.metrics import ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLMCEfSo2-Ta"
      },
      "source": [
        "### transforms for downstream tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Y-XzUQ9KouOQ"
      },
      "outputs": [],
      "source": [
        "# transform_test = transforms.Compose([\n",
        "#         # transforms.Resize(224),\n",
        "#         # transforms.ToTensor(),\n",
        "#         transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "#     ])\n",
        "# s=0.5\n",
        "# color_jitter = transforms.ColorJitter(0.4*4, 0.4*s, 0.4*s, 0.2*s)\n",
        "# transform_eval = transforms.Compose([\n",
        "#         # transforms.RandomResizedCrop((224,224), scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333)),\n",
        "#         transforms.RandomHorizontalFlip(p=0.5),\n",
        "#         transforms.RandomApply([color_jitter], p=0.5), \n",
        "#         transforms.RandomGrayscale(p=0.4),\n",
        "#         # transforms.Resize(224),\n",
        "#         # transforms.ToTensor(),\n",
        "#         # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "#     ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([25500, 3, 224, 224])\n",
            "torch.Size([25500])\n",
            "torch.Size([10025, 3, 224, 224])\n",
            "torch.Size([10025])\n"
          ]
        }
      ],
      "source": [
        "loaded_data = torch.load(\"/home/rishabh.mondal/Brick-Kilns-project/albk_rishabh/tensor_data/test_data.pt\")\n",
        "loaded_data1 = torch.load(\"/home/rishabh.mondal/Brick-Kilns-project/albk_rishabh/tensor_data/data.pt\")\n",
        "images= loaded_data1['images']\n",
        "labels = loaded_data1['labels']\n",
        "images = images / 255\n",
        "# images = (images - images.mean(dim=(0, 2, 3), keepdim=True)) / images.std(dim=(0, 2, 3), keepdim=True)\n",
        "images1 = loaded_data['images']\n",
        "labels1 = loaded_data['labels']\n",
        "images1 = images1 / 255\n",
        "# images1 = (images1 - images1.mean(dim=(0, 2, 3), keepdim=True)) / images1.std(dim=(0, 2, 3), keepdim=True)\n",
        "# print(images1.shape)\n",
        "# print(labels1.shape)\n",
        "# print(images.shape)\n",
        "# print(labels.shape)\n",
        "train_images = images\n",
        "train_labels = labels\n",
        "test_images = images1\n",
        "test_labels = labels1\n",
        "print(train_images.shape)\n",
        "print(train_labels.shape)\n",
        "print(test_images.shape)\n",
        "print(test_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# loaded_datad1= torch.load(\"/home/rishabh.mondal/Brick-Kilns-project/albk_rishabh/tensor_data_final/delhi_data_90.pt\")\n",
        "# imagesd= loaded_datad1['images']\n",
        "# labelsd = loaded_datad1['labels']\n",
        "\n",
        "# images1 = images1 / 255\n",
        "# images1 = (images1 print(images1.shape)\n",
        "# print(labels1.shape)- images1.mean(dim=(0, 2, 3), keepdim=True)) / images1.std(dim=(0, 2, 3), keepdim=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# train_images= torch.cat((train_images,imagesd),0)\n",
        "# train_labels= torch.cat((train_labels,labelsd),0)\n",
        "# print(train_images.shape)\n",
        "# print(train_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.float32, torch.uint8, torch.float32, torch.uint8)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_images.dtype, train_labels.dtype, test_images.dtype, test_labels.dtype\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# train_labels = train_labels.type(torch.uint8)\n",
        "# test_labels = test_labels.type(torch.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# train_images.dtype, train_labels.dtype, test_images.dtype, test_labels.dtype\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of train labels with value 1: tensor(1697)\n",
            "Number of test labels with value 1: tensor(1042)\n"
          ]
        }
      ],
      "source": [
        "train_labels_count = (train_labels == 1).sum()\n",
        "test_labels_count = (test_labels == 1).sum()\n",
        "\n",
        "print(\"Number of train labels with value 1:\", train_labels_count)\n",
        "print(\"Number of test labels with value 1:\", test_labels_count)\n",
        "# test_images=transform_test(test_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data preporcessing for how much percentage of the data is used for finetune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# train_images=transform_eval(train_images)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print(train_images.shape)\n",
        "# print(test_images.shape)\n",
        "train_set=torch.utils.data.TensorDataset(train_images,train_labels)\n",
        "test_set=torch.utils.data.TensorDataset(test_images,test_labels)\n",
        "train_loader=torch.utils.data.DataLoader(train_set,batch_size=512,shuffle=True,num_workers=8)\n",
        "test_loader=torch.utils.data.DataLoader(test_set,batch_size=512,shuffle=False,num_workers=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "25500"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rishabh.mondal/miniconda3/envs/torch_space/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/home/rishabh.mondal/miniconda3/envs/torch_space/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "EfficientNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2dNormActivation(\n",
              "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU(inplace=True)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (2): Conv2dNormActivation(\n",
              "            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
              "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
              "      )\n",
              "      (1): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
              "      )\n",
              "      (1): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
              "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (4): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
              "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
              "      )\n",
              "      (1): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
              "      )\n",
              "      (2): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
              "      )\n",
              "      (1): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
              "      )\n",
              "      (2): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (6): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
              "      )\n",
              "      (1): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
              "      )\n",
              "      (2): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
              "      )\n",
              "      (3): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (7): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (8): Conv2dNormActivation(\n",
              "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.2, inplace=True)\n",
              "    (1): Linear(in_features=1280, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "base_encoder=torchvision.models.efficientnet_b0(pretrained=True)\n",
        "# base_encoder\n",
        "base_encoder.classifier[1]=nn.Linear(1280,2)\n",
        "base_encoder.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### fine-tune the downstram model  and predict on test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0665)\n",
            "tensor(0.9335)\n"
          ]
        }
      ],
      "source": [
        "class_0_weight=train_labels_count/len(train_images)\n",
        "print(class_0_weight)\n",
        "class_1_weight=1-class_0_weight\n",
        "print(class_1_weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# nn.CrossEntropyLoss??"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Loss: 0.21256689541830737, Accuracy: 0.8942745098039215, Precision: 0.3812693130496791, Recall: 0.9451974071891573, F1: 0.5433604336043361\n",
            "Test - Accuracy: 0.8824937655860349, Precision: 0.4672131147540984, Recall: 0.9299424184261037, F1: 0.6219512195121951\n",
            "Epoch 1, Loss: 0.0596610213728512, Accuracy: 0.9809019607843137, Precision: 0.7851083883129123, Recall: 0.9817324690630524, F1: 0.8724797067295104\n",
            "Test - Accuracy: 0.9237905236907731, Precision: 0.5877525252525253, Recall: 0.8934740882917467, F1: 0.7090632140137091\n",
            "Epoch 2, Loss: 0.03109229525280934, Accuracy: 0.9895686274509804, Precision: 0.8690046415678184, Recall: 0.9929286977018268, F1: 0.9268426842684268\n",
            "Test - Accuracy: 0.9602992518703242, Precision: 0.78, Recall: 0.8608445297504799, F1: 0.8184306569343066\n",
            "Epoch 3, Loss: 0.01767047964576997, Accuracy: 0.9937254901960785, Precision: 0.915180983252296, Recall: 0.9982321744254566, F1: 0.9549041713641487\n",
            "Test - Accuracy: 0.9655860349127182, Precision: 0.850956696878147, Recall: 0.8109404990403071, F1: 0.8304668304668305\n",
            "Epoch 4, Loss: 0.011814650405855739, Accuracy: 0.996078431372549, Precision: 0.9458403126744835, Recall: 0.9982321744254566, F1: 0.9713302752293578\n",
            "Test - Accuracy: 0.9612967581047381, Precision: 0.8902147971360382, Recall: 0.7159309021113244, F1: 0.7936170212765957\n",
            "Epoch 5, Loss: 0.01160932684879677, Accuracy: 0.996, Precision: 0.9467787114845938, Recall: 0.995875073659399, F1: 0.9707064905226881\n",
            "Test - Accuracy: 0.9496259351620948, Precision: 0.7213520197856554, Recall: 0.8397312859884837, F1: 0.7760532150776054\n",
            "Epoch 6, Loss: 0.010581244042106704, Accuracy: 0.995921568627451, Precision: 0.9457190822607723, Recall: 0.995875073659399, F1: 0.9701492537313433\n",
            "Test - Accuracy: 0.9588029925187033, Precision: 0.8356456776947705, Recall: 0.7514395393474088, F1: 0.7913087417887822\n",
            "Epoch 7, Loss: 0.014647448689622037, Accuracy: 0.9952941176470588, Precision: 0.9368421052631579, Recall: 0.9964643488509134, F1: 0.9657338663620789\n",
            "Test - Accuracy: 0.958004987531172, Precision: 0.8335123523093448, Recall: 0.744721689059501, F1: 0.7866193613786113\n",
            "Epoch 8, Loss: 0.015762664397557576, Accuracy: 0.9941960784313726, Precision: 0.92253136933988, Recall: 0.9964643488509134, F1: 0.9580736543909348\n",
            "Test - Accuracy: 0.9562094763092269, Precision: 0.8011988011988012, Recall: 0.7696737044145874, F1: 0.7851199216837983\n",
            "Epoch 9, Loss: 0.017938485786976183, Accuracy: 0.9942745098039215, Precision: 0.9253976961053209, Recall: 0.9941072480848556, F1: 0.9585227272727271\n",
            "Test - Accuracy: 0.9487281795511222, Precision: 0.7672064777327935, Recall: 0.727447216890595, F1: 0.7467980295566502\n",
            "Epoch 10, Loss: 0.008081634847849023, Accuracy: 0.9970980392156863, Precision: 0.9597733711048159, Recall: 0.9982321744254566, F1: 0.9786250722125939\n",
            "Test - Accuracy: 0.956708229426434, Precision: 0.859338061465721, Recall: 0.6976967370441459, F1: 0.7701271186440679\n",
            "Epoch 11, Loss: 0.008158321501139333, Accuracy: 0.9968627450980392, Precision: 0.9565217391304348, Recall: 0.9982321744254566, F1: 0.9769319492502884\n",
            "Test - Accuracy: 0.9588029925187033, Precision: 0.8104639684106614, Recall: 0.7879078694817658, F1: 0.7990267639902676\n",
            "Epoch 12, Loss: 0.0073406352163749, Accuracy: 0.9976470588235294, Precision: 0.9674471730439749, Recall: 0.9982321744254566, F1: 0.982598607888631\n",
            "Test - Accuracy: 0.9593017456359102, Precision: 0.8315899581589958, Recall: 0.7629558541266794, F1: 0.7957957957957957\n",
            "Epoch 13, Loss: 0.0027271162720132326, Accuracy: 0.9988627450980392, Precision: 0.9831981460023175, Recall: 1.0, F1: 0.9915278995033595\n",
            "Test - Accuracy: 0.9613965087281795, Precision: 0.9048207663782447, Recall: 0.7024952015355086, F1: 0.7909238249594813\n",
            "Epoch 14, Loss: 0.00460878114906304, Accuracy: 0.9985882352941177, Precision: 0.9803354540196646, Recall: 0.9988214496169712, F1: 0.989492119089317\n",
            "Test - Accuracy: 0.9581047381546135, Precision: 0.828752642706131, Recall: 0.7523992322456814, F1: 0.7887323943661971\n",
            "Epoch 15, Loss: 0.003918533778073741, Accuracy: 0.9984705882352941, Precision: 0.9786374133949192, Recall: 0.9988214496169712, F1: 0.9886264216972879\n",
            "Test - Accuracy: 0.9518204488778055, Precision: 0.7664442326024785, Recall: 0.7715930902111324, F1: 0.7690100430416068\n",
            "Epoch 16, Loss: 0.0051981330055232144, Accuracy: 0.9981960784313726, Precision: 0.97524467472654, Recall: 0.9982321744254566, F1: 0.986604542807222\n",
            "Test - Accuracy: 0.9339650872817955, Precision: 0.6532258064516129, Recall: 0.7773512476007678, F1: 0.7099035933391761\n",
            "Epoch 17, Loss: 0.012705696728007466, Accuracy: 0.9958823529411764, Precision: 0.9451901565995525, Recall: 0.995875073659399, F1: 0.96987087517934\n",
            "Test - Accuracy: 0.9553117206982543, Precision: 0.7582608695652174, Recall: 0.836852207293666, F1: 0.7956204379562044\n",
            "Epoch 18, Loss: 0.0054036883536507105, Accuracy: 0.998, Precision: 0.9719036697247706, Recall: 0.9988214496169712, F1: 0.9851787271142111\n",
            "Test - Accuracy: 0.9402493765586035, Precision: 0.6530753282653766, Recall: 0.9069097888675623, F1: 0.7593411008437123\n",
            "Epoch 19, Loss: 0.005842612406458048, Accuracy: 0.9975686274509804, Precision: 0.9668760708166761, Recall: 0.9976428992339422, F1: 0.9820185614849187\n",
            "Test - Accuracy: 0.9570074812967581, Precision: 0.7890255439924314, Recall: 0.800383877159309, F1: 0.7946641257741781\n",
            "Epoch 20, Loss: 0.003093301079144665, Accuracy: 0.9986666666666667, Precision: 0.9814707585408222, Recall: 0.9988214496169712, F1: 0.990070093457944\n",
            "Test - Accuracy: 0.9587032418952618, Precision: 0.810891089108911, Recall: 0.7859884836852208, F1: 0.7982456140350879\n",
            "Epoch 21, Loss: 0.004921401811215808, Accuracy: 0.9978431372549019, Precision: 0.9696796338672768, Recall: 0.9988214496169712, F1: 0.9840348330914368\n",
            "Test - Accuracy: 0.9591022443890275, Precision: 0.8550561797752809, Recall: 0.7303262955854126, F1: 0.7877846790890268\n",
            "Epoch 22, Loss: 0.0062139348358865466, Accuracy: 0.998, Precision: 0.9713631156930126, Recall: 0.9994107248084856, F1: 0.9851873366250364\n",
            "Test - Accuracy: 0.9627930174563591, Precision: 0.8334995014955134, Recall: 0.8023032629558541, F1: 0.8176039119804401\n",
            "Epoch 23, Loss: 0.0047980384297723715, Accuracy: 0.998313725490196, Precision: 0.9769319492502884, Recall: 0.9982321744254566, F1: 0.9874672107257358\n",
            "Test - Accuracy: 0.9598004987531172, Precision: 0.8676639815880323, Recall: 0.7236084452975048, F1: 0.7891156462585033\n",
            "Epoch 24, Loss: 0.004710487259853193, Accuracy: 0.9983529411764706, Precision: 0.9774956722446624, Recall: 0.9982321744254566, F1: 0.9877551020408163\n",
            "Test - Accuracy: 0.9600997506234414, Precision: 0.8104448742746615, Recall: 0.8042226487523992, F1: 0.8073217726396918\n",
            "Epoch 25, Loss: 0.0014994360680267325, Accuracy: 0.9994509803921569, Precision: 0.9918176504967855, Recall: 1.0, F1: 0.9958920187793427\n",
            "Test - Accuracy: 0.9617955112219452, Precision: 0.8681564245810056, Recall: 0.7456813819577736, F1: 0.8022715539494064\n",
            "Epoch 26, Loss: 0.0009152062859377075, Accuracy: 0.9997254901960785, Precision: 0.9958920187793427, Recall: 1.0, F1: 0.9979417818288738\n",
            "Test - Accuracy: 0.9582044887780549, Precision: 0.8677685950413223, Recall: 0.7053742802303263, F1: 0.7781895182636315\n",
            "Epoch 27, Loss: 0.006019603740643052, Accuracy: 0.998078431372549, Precision: 0.9735632183908046, Recall: 0.9982321744254566, F1: 0.9857433808553971\n",
            "Test - Accuracy: 0.9581047381546135, Precision: 0.8199588477366255, Recall: 0.7648752399232246, F1: 0.791459781529295\n",
            "Epoch 28, Loss: 0.011192036731424285, Accuracy: 0.9968235294117647, Precision: 0.9570135746606335, Recall: 0.9970536240424278, F1: 0.9766233766233767\n",
            "Test - Accuracy: 0.9499251870324189, Precision: 0.7922077922077922, Recall: 0.7024952015355086, F1: 0.7446592065106816\n",
            "Epoch 29, Loss: 0.0026532099446619625, Accuracy: 0.9989019607843137, Precision: 0.983768115942029, Recall: 1.0, F1: 0.9918176504967855\n",
            "Test - Accuracy: 0.9479301745635911, Precision: 0.8376623376623377, Recall: 0.6190019193857965, F1: 0.7119205298013245\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# criterion = nn.CrossEntropyLoss(weight=torch.tensor([class_0_weight, class_1_weight]).to(device))\n",
        "criterion=nn.Focal\n",
        "optimizer = torch.optim.Adam(base_encoder.parameters(), lr=3e-4)\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "train_precisions = []\n",
        "train_recalls = []\n",
        "train_f1_scores = []\n",
        "test_f1_scores = []\n",
        "test_losses = []\n",
        "test_accuracies = []\n",
        "test_precisions = []\n",
        "test_recalls = []\n",
        "for epoch in range(30):\n",
        "    base_encoder.train()\n",
        "    true_labels = []\n",
        "    pred_labels = []        \n",
        "    running_loss = 0.0\n",
        "    for i ,(inputs, labels) in enumerate(train_loader):\n",
        "        inputs = inputs.to('cuda')\n",
        "        labels = labels.to('cuda')\n",
        "        optimizer.zero_grad()\n",
        "        output = base_encoder(inputs)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, preds = torch.max(output, 1)\n",
        "        true_labels.extend(labels.data.cpu().numpy())\n",
        "        pred_labels.extend(preds.data.cpu().numpy())\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_accuracy = accuracy_score(true_labels, pred_labels)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "    train_precision = precision_score(true_labels, pred_labels)\n",
        "    train_precisions.append(train_precision)\n",
        "    train_recall = recall_score(true_labels, pred_labels)\n",
        "    train_recalls.append(train_recall)\n",
        "    train_f1 = f1_score(true_labels, pred_labels)\n",
        "    train_f1_scores.append(train_f1)\n",
        "    print(f'Epoch {epoch}, Loss: {epoch_loss}, Accuracy: {train_accuracy}, Precision: {train_precision}, Recall: {train_recall}, F1: {train_f1}')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        base_encoder.eval()\n",
        "        true_labels = []\n",
        "        pred_labels = []\n",
        "        for i, (inputs, labels) in enumerate(test_loader):\n",
        "            inputs = inputs.to('cuda')\n",
        "            labels = labels.to('cuda')\n",
        "            output = base_encoder(inputs)\n",
        "            _, preds = torch.max(output, 1)\n",
        "            true_labels.extend(labels.data.cpu().numpy())\n",
        "            pred_labels.extend(preds.data.cpu().numpy())\n",
        "    test_accuracy = accuracy_score(true_labels, pred_labels)\n",
        "    test_accuracies.append(test_accuracy)\n",
        "    test_precision = precision_score(true_labels, pred_labels)\n",
        "    test_precisions.append(test_precision)\n",
        "    test_recall = recall_score(true_labels, pred_labels)\n",
        "    test_recalls.append(test_recall)\n",
        "    test_f1 = f1_score(true_labels, pred_labels)\n",
        "    test_f1_scores.append(test_f1)\n",
        "    print(f'Test - Accuracy: {test_accuracy}, Precision: {test_precision}, Recall: {test_recall}, F1: {test_f1}')\n",
        "\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "result_dict = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Acc: 94.793% (9503/10025)\n",
            "10025 10025\n",
            "Accuracy:  0.9479301745635911\n",
            "Precision:  0.8376623376623377\n",
            "Recall:  0.6190019193857965\n",
            "F1 Score:  0.7119205298013245\n",
            "Confusion Matrix:\n",
            "[[8858  125]\n",
            " [ 397  645]]\n",
            "Class-specific Accuracy: [0.98608483 0.61900192]\n",
            "Class-specific Precision: [0.95710427 0.83766234]\n",
            "Class-specific Recall: [0.98608483 0.61900192]\n",
            "Class-specific F1 Score: [0.97137844 0.71192053]\n",
            "{'5D% NoSimCLR': {'accuracy': 0.9479301745635911, 'f1': 0.7119205298013245, 'precision': 0.8376623376623377, 'recall': 0.6190019193857965}}\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "percent = \"5D%\"\n",
        "ssl = \"NoSimCLR\"\n",
        "with torch.no_grad():    \n",
        "    base_encoder.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    y_pred = []\n",
        "    y_test = []\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            output = base_encoder(inputs)\n",
        "            _, preds = torch.max(output, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += preds.eq(targets).sum().item()\n",
        "            y_pred.extend(preds.cpu().numpy())\n",
        "            y_test.extend(targets.cpu().numpy())\n",
        "    \n",
        "    y_pred = np.array(y_pred)\n",
        "    y_test = np.array(y_test)\n",
        "    \n",
        "    print('Test Acc: %.3f%% (%d/%d)' % (100.*correct/total, correct, total))\n",
        "    print(len(y_pred), len(y_test))\n",
        "    \n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    \n",
        "    print(\"Accuracy: \", accuracy)\n",
        "    print(\"Precision: \", precision)\n",
        "    print(\"Recall: \", recall)\n",
        "    print(\"F1 Score: \", f1)\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "    \n",
        "    # If needed, class-specific metrics\n",
        "    class_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
        "    class_precision = precision_score(y_test, y_pred, average=None)\n",
        "    class_recall = recall_score(y_test, y_pred, average=None)\n",
        "    class_f1 = f1_score(y_test, y_pred, average=None)\n",
        "\n",
        "    print(\"Class-specific Accuracy:\", class_accuracy)\n",
        "    print(\"Class-specific Precision:\", class_precision)\n",
        "    print(\"Class-specific Recall:\", class_recall)\n",
        "    print(\"Class-specific F1 Score:\", class_f1)\n",
        "    result_dict[f\"{percent} {ssl}\"] = {\"accuracy\": accuracy, \"f1\": f1, \"precision\": precision, \"recall\": recall}\n",
        "    print(result_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# y_pred,ytest=prdict(net_eval, test_loader, \"30%\", \"ssl\", device,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# result_dict = {\n",
        "#     \"100% SimCLR\": {\n",
        "#         \"Accuracy\": 0.9012222222222223,\n",
        "#         \"Precision\": 0.5627563576702215,\n",
        "#         \"Recall\": 0.6583493282149712,\n",
        "#         \"F1 Score\": 0.60111455108358\n",
        "#     },\n",
        "#     \"100% SimCLR augmentaion\": {\n",
        "#         'Accuracy':  0.9066666666666666,\n",
        "#         'Precision':  0.6185446009389671,\n",
        "#         'Recall':  0.5057581573896354,\n",
        "#         'F1 Score':  0.5564941921858501\n",
        "#     },\n",
        "#     \"100% no ssl\": {\n",
        "#         'Accuracy':  0.9072222222222223,\n",
        "#         'Precision':  0.6624803767660911,\n",
        "#         'Recall':  0.4049904030710173,\n",
        "#         'F1 Score':  0.5026801667659321\n",
        "#     },\n",
        "#     \"100% SimCLR focal loss\": {\n",
        "#         'Accuracy':  0.9163333333333333,\n",
        "#         'Precision':  0.7680890538033395,\n",
        "#         'Recall':  0.39731285988483683,\n",
        "#         'F1 Score':  0.523719165085389\n",
        "#     }\n",
        "# }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'5D% NoSimCLR': {'accuracy': 0.9479301745635911, 'f1': 0.7119205298013245, 'precision': 0.8376623376623377, 'recall': 0.6190019193857965}}\n"
          ]
        }
      ],
      "source": [
        "print(result_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "file_path = \"/home/rishabh.mondal/Brick-Kilns-project/albk_rishabh/albk_v2/SSL_Experiments/SimCLR_experiments/siclr_result/5D%_no_ssl.pkl\"\n",
        "with open(file_path, \"wb\") as file:\n",
        "    pickle.dump(result_dict, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import pickle\n",
        "\n",
        "# # Load the dictionaries from the files\n",
        "# with open(\"dictionary1_ssl.pkl\", \"rb\") as file1, open(\"merged_dictionary_main.pkl\", \"rb\") as file2:\n",
        "#     dict1 = pickle.load(file1)\n",
        "#     dict2 = pickle.load(file2)\n",
        "\n",
        "# # Merge the dictionaries\n",
        "# merged_dict = {**dict1, **dict2}\n",
        "\n",
        "# # Save the merged dictionary to a file\n",
        "# with open(\"merged_dictionary_main.pkl\", \"wb\") as file:\n",
        "#     pickle.dump(merged_dict, file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'100%+1% SimCLR': {'accuracy': 0.9135555555555556, 'f1': 0.5261875761266749, 'precision': 0.72, 'recall': 0.4145873320537428}}\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "# Load the merged dictionary from the file\n",
        "with open(\"/home/rishabh.mondal/Brick-Kilns-project/albk_rishabh/albk_v2/SSL_Experiments/SimCLR_experiments/siclr_result/100+1_ssl.pkl\", \"rb\") as file:\n",
        "    merged_dict = pickle.load(file)\n",
        "\n",
        "# Print the merged dictionary\n",
        "print(merged_dict)\n",
        "# "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>100%+1% SimCLR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>accuracy</th>\n",
              "      <td>0.913556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1</th>\n",
              "      <td>0.526188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.720000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.414587</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           100%+1% SimCLR\n",
              "accuracy         0.913556\n",
              "f1               0.526188\n",
              "precision        0.720000\n",
              "recall           0.414587"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "resdf = pd.DataFrame(merged_dict)\n",
        "resdf\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# #list to tensor\n",
        "# y_pred = torch.tensor(y_pred)\n",
        "# y_test = torch.tensor(y_test)\n",
        "# def results(y_labels,y_pred,plot_confusion = False):\n",
        "#     y_labels = y_labels.to(device) \n",
        "#     y_pred = y_pred.to(device)\n",
        "#     print(f\"Accuracy = {(y_labels == y_pred).float().mean()}\")\n",
        "#     if plot_confusion:\n",
        "#         cm = confusion_matrix(y_labels.cpu(), y_pred.cpu())\n",
        "#         unique_labels = np.unique(y_labels.cpu())\n",
        "#         cm_display = ConfusionMatrixDisplay(cm, display_labels=unique_labels).plot(values_format='d', cmap='Blues')\n",
        "#         plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "# results(y_test,y_pred,plot_confusion = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# # Assuming df is your DataFrame\n",
        "# df = pd.read_csv(\"/home/rishabh.mondal/Brick-Kilns-project/albk_rishabh/albk_v2/SSL_Experiments/patchfill_experiments/SSL_Result.csv\")\n",
        "\n",
        "# # Extract the '100% SSL' column and convert it to a dictionary\n",
        "# ssl_dict = df.set_index('Results')['100% SSL'].to_dict()\n",
        "\n",
        "# # Display the created dictionary\n",
        "# ssl_dict={'100% ssl':{'accuracy': 0.913217, 'f1': 0.696559, 'precision': 0.797193, 'recall': 0.654645}}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "# file_path = \"dictionary2.pkl\"\n",
        "\n",
        "# # Open the file in write mode\n",
        "# with open(file_path, \"wb\") as file:\n",
        "#     # Write the dictionary to the file\n",
        "#     pickle.dump(ssl_dict, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import pickle\n",
        "\n",
        "# # Load the dictionaries from the files\n",
        "# with open(\"merged_dictionary.pkl\", \"rb\") as file1, open(\"dictionary2.pkl\", \"rb\") as file2:\n",
        "#     dict1 = pickle.load(file1)\n",
        "#     dict2 = pickle.load(file2)\n",
        "\n",
        "# # Merge the dictionaries\n",
        "# merged_dict = {**dict1, **dict2}\n",
        "\n",
        "# # Save the merged dictionary to a file\n",
        "# with open(\"merged_dictionary.pkl\", \"wb\") as file:\n",
        "#     pickle.dump(merged_dict, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "# resdf = pd.DataFrame(merged_dict)\n",
        "# resdf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "135ac4e0eaf64ddb904847480ca09580": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d1db6dd5e074356a8a8880ad7a70251": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7d7f05d7cfe4be1a66ca21f27237fcc",
            "placeholder": "",
            "style": "IPY_MODEL_135ac4e0eaf64ddb904847480ca09580",
            "value": "100%"
          }
        },
        "6bde15cb4e5843918d9eae09e2538a62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "79fdf90d505645548201d18a86662357": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8341064b90d84f78b37152a978462746": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4d1db6dd5e074356a8a8880ad7a70251",
              "IPY_MODEL_d1c65768583b4a46894b45623f875bf7",
              "IPY_MODEL_e727713e85a94cc180b56fd0638e47ed"
            ],
            "layout": "IPY_MODEL_8ee9f2e48341478c87553fef21bcb17c"
          }
        },
        "8ee9f2e48341478c87553fef21bcb17c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6442b6118654145b4ccb7198a443ce5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7d7f05d7cfe4be1a66ca21f27237fcc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1c65768583b4a46894b45623f875bf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6442b6118654145b4ccb7198a443ce5",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6bde15cb4e5843918d9eae09e2538a62",
            "value": 170498071
          }
        },
        "e1a1727432c94edbad14465f8282b26f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e727713e85a94cc180b56fd0638e47ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1a1727432c94edbad14465f8282b26f",
            "placeholder": "",
            "style": "IPY_MODEL_79fdf90d505645548201d18a86662357",
            "value": " 170498071/170498071 [00:13&lt;00:00, 14351878.49it/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
